schema_version: "1.0"
name: "Bluebook Citation Evaluation"
version: "1.0"
description: "Evaluates legal citations according to The Bluebook citation format rules."
author: "Lake Merritt Team"

ingestion:
  type: "csv"

pipeline:
  - name: "semantic_judge"
    scorer: "llm_judge"
    config:
      provider: "openai"
      model: "gpt-4o"
      threshold: 0.5            # formerly pass_threshold
      system_prompt: |
        You are a legal citation expert following The Bluebook rules.
        Return only a JSON object with "score" (float 0-1) and "reasoning" (string).
      user_prompt_template: |
        ### Instructions
        Compare the student's citation to the expected one. Ignore punctuation or spacing
        differences that do not change the legal authority.

        ### Scoring Rubric
        * 1.0 – Substantively identical citations.
        * 0.5 – Same authority but minor Bluebook formatting issues.
        * 0.0 – References a different or incorrect authority.

        ### Data
        * **Expected Citation:** {expected_output}
        * **Student Citation:**  {output}
    on_fail: "continue"